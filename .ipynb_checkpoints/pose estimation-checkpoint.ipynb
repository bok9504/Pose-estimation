{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 기존 Pose Estimate 수행"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 웹캠으로 영상을 받아와 Pose Estimate 수행"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "어플 상 화면 : 카메라가 받은 FPS로 그대로 출력\n",
    "\n",
    "Pose Estimate : FPS 2 단위로 알로리즘 추출 후 특정 자세 추출시 촬영 수행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-11T09:00:21.856444Z",
     "start_time": "2020-11-11T09:00:21.849437Z"
    }
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-11T09:12:37.041046Z",
     "start_time": "2020-11-11T09:12:36.853973Z"
    }
   },
   "outputs": [],
   "source": [
    "# fashion_pose.py : MPII를 사용한 신체부위 검출\n",
    "\n",
    "\n",
    "# MPII에서 각 파트 번호, 선으로 연결될 POSE_PAIRS\n",
    "BODY_PARTS = { \"Head\": 0, \"Neck\": 1, \"RShoulder\": 2, \"RElbow\": 3, \"RWrist\": 4,\n",
    "                \"LShoulder\": 5, \"LElbow\": 6, \"LWrist\": 7, \"RHip\": 8, \"RKnee\": 9,\n",
    "                \"RAnkle\": 10, \"LHip\": 11, \"LKnee\": 12, \"LAnkle\": 13, \"Chest\": 14,\n",
    "                \"Background\": 15 }\n",
    "\n",
    "POSE_PAIRS = [ [\"Head\", \"Neck\"], [\"Neck\", \"RShoulder\"], [\"RShoulder\", \"RElbow\"],\n",
    "                [\"RElbow\", \"RWrist\"], [\"Neck\", \"LShoulder\"], [\"LShoulder\", \"LElbow\"],\n",
    "                [\"LElbow\", \"LWrist\"], [\"Neck\", \"Chest\"], [\"Chest\", \"RHip\"], [\"RHip\", \"RKnee\"],\n",
    "                [\"RKnee\", \"RAnkle\"], [\"Chest\", \"LHip\"], [\"LHip\", \"LKnee\"], [\"LKnee\", \"LAnkle\"] ]\n",
    "    \n",
    "# 각 파일 path\n",
    "protoFile = \"pose/mpi/pose_deploy_linevec_faster_4_stages.prototxt\"\n",
    "weightsFile = \"pose/mpi/pose_iter_160000.caffemodel\"\n",
    "\n",
    " \n",
    "# 위의 path에 있는 network 불러오기\n",
    "net = cv2.dnn.readNetFromCaffe(protoFile, weightsFile)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-11T09:12:37.100984Z",
     "start_time": "2020-11-11T09:12:37.084994Z"
    }
   },
   "outputs": [],
   "source": [
    "def pose_estimate(frame):\n",
    "\n",
    "    # frame.shape = 불러온 이미지에서 height, width, color 받아옴\n",
    "    inWidth = 368\n",
    "    inHeight = 368\n",
    "    frameHeight, frameWidth, _ = frame.shape\n",
    "\n",
    "    # network에 넣기위해 전처리\n",
    "    inpBlob = cv2.dnn.blobFromImage(frame, 1.0 / 255, (inWidth, inHeight), (0, 0, 0), swapRB=False, crop=False)\n",
    "\n",
    "    # network에 넣어주기\n",
    "    net.setInput(inpBlob)\n",
    "\n",
    "    # 결과 받아오기\n",
    "    output = net.forward()\n",
    "\n",
    "    # output.shape[0] = 이미지 ID, [1] = 출력 맵의 높이, [2] = 너비\n",
    "    H = output.shape[2]\n",
    "    W = output.shape[3]\n",
    "\n",
    "    # 키포인트 검출시 이미지에 그려줌\n",
    "    points = []\n",
    "    for i in range(0,15):\n",
    "        # 해당 신체부위 신뢰도 얻음.\n",
    "        probMap = output[0, i, :, :]\n",
    "\n",
    "        # global 최대값 찾기\n",
    "        minVal, prob, minLoc, point = cv2.minMaxLoc(probMap)\n",
    "\n",
    "        # 원래 이미지에 맞게 점 위치 변경\n",
    "        x = (frameWidth * point[0]) / W\n",
    "        y = (frameHeight * point[1]) / H\n",
    "\n",
    "        # 키포인트 검출한 결과가 0.1보다 크면(검출한곳이 위 BODY_PARTS랑 맞는 부위면) points에 추가, 검출했는데 부위가 없으면 None으로    \n",
    "        if prob > 0.1 :    \n",
    "            cv2.circle(frame, (int(x), int(y)), 3, (0, 255, 255), thickness=-1, lineType=cv2.FILLED)       # circle(그릴곳, 원의 중심, 반지름, 색)\n",
    "            cv2.putText(frame, \"{}\".format(i), (int(x), int(y)), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 1, lineType=cv2.LINE_AA)\n",
    "            points.append((int(x), int(y)))\n",
    "        else :\n",
    "            points.append(None)\n",
    "\n",
    "    # 이미지 복사\n",
    "    frameCopy = frame\n",
    "\n",
    "    # 각 POSE_PAIRS별로 선 그어줌 (머리 - 목, 목 - 왼쪽어깨, ...)\n",
    "    for pair in POSE_PAIRS:\n",
    "        partA = pair[0]             # Head\n",
    "        partA = BODY_PARTS[partA]   # 0\n",
    "        partB = pair[1]             # Neck\n",
    "        partB = BODY_PARTS[partB]   # 1\n",
    "\n",
    "        #print(partA,\" 와 \", partB, \" 연결\\n\")\n",
    "        if points[partA] and points[partB]:\n",
    "            cv2.line(frameCopy, points[partA], points[partB], (0, 255, 0), 2)\n",
    "            \n",
    "    return frameCopy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-11T09:12:37.815388Z",
     "start_time": "2020-11-11T09:12:37.798286Z"
    }
   },
   "outputs": [],
   "source": [
    "# 카메라를 구동하여 흑백으로 표출해주는 함수\n",
    "\n",
    "def showVideo(FPS):\n",
    "\n",
    "    try:\n",
    "        print('카메라를 구동합니다.')\n",
    "        cap = cv2.VideoCapture(0) # VideoCapture 객체 생성 -> 구동할 장치 번호 입력(캠이 하나임으로 0번)\n",
    "    except:                      # 만약 캠구동이 아니라 저장된 파일을 재생하기 원할 시, 경로와 파일이름 입력\n",
    "        print('카메라 구동 실패')\n",
    "        return\n",
    "\n",
    "    cap.set(3, 480) # 프레임 크기 설정\n",
    "    cap.set(4, 320)    \n",
    "    prev_time = 0\n",
    "    \n",
    "    while True:\n",
    "        ret, frame = cap.read() # 재생되는 비디오를 한 프레임씩 읽기 \n",
    "        frame = cv2.flip(frame, 1) # 제대로 읽을 시에 ret : True or False, frame : 읽은 프레임\n",
    "        current_time = time.time() - prev_time\n",
    "        \n",
    "        if not ret:\n",
    "            print('비디오 읽기 오류')\n",
    "            break\n",
    "        \n",
    "        framePose = pose_estimate(frame)\n",
    "        \n",
    "        if (ret is True) and (current_time > 1./ FPS) :\n",
    "            prev_time = time.time()\n",
    "            cv2.imshow('video', framePose) # 변환한 프레임을 화면에 디스플레이\n",
    "        \n",
    "        \n",
    "        k = cv2.waitKey(1) & 0xFF\n",
    "        if k == 27:\n",
    "            print('카메라 구동을 종료합니다.')\n",
    "            break\n",
    "    \n",
    "    cap.release() # 오픈한 cap 객체 해제 **** 필수 ****\n",
    "    cv2.destroyAllWindows() # 윈도우 창 답기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-11T09:34:08.292046Z",
     "start_time": "2020-11-11T09:33:11.369846Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "카메라를 구동합니다.\n",
      "카메라 구동을 종료합니다.\n"
     ]
    }
   ],
   "source": [
    "showVideo(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-11T09:14:28.259800Z",
     "start_time": "2020-11-11T09:14:27.837833Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time : 0.4129946231842041\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "frame = cv2.imread('images/single.jpg')\n",
    "frameOut = pose_estimate(frame)\n",
    "cv2.imshow(\"Output-Keypoints\",frameOut)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "print('time :', time.time() - start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 프레임 조절"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-11T08:40:52.741164Z",
     "start_time": "2020-11-11T08:39:54.189022Z"
    }
   },
   "outputs": [],
   "source": [
    "input_source = \"../2.데이터/0.dataset/test.mp4\"\n",
    "cap = cv2.VideoCapture(input_source)\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read() # 재생되는 비디오를 한 프레임씩 읽기 \n",
    "    frame = cv2.flip(frame, 1) # 제대로 읽을 시에 ret : True or False, frame : 읽은 프레임\n",
    "\n",
    "    if not ret:\n",
    "        print('비디오 읽기 오류')\n",
    "        break\n",
    "\n",
    "    framePose = pose_estimate(frame)\n",
    "\n",
    "    cv2.imshow('video', framePose) # 변환한 프레임을 화면에 디스플레이\n",
    "    \n",
    "    k = cv2.waitKey(1)\n",
    "    if k == 27: break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
